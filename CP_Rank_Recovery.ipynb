{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6a05949c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adapted from code supplements from papers:\n",
    "#1.`Modewise Operators, the Tensor Restricted Isometry Property, and Low-Rank Tensor Recovery\" by Mark A. Iwen, Deanna Needell, Michael Perlmutter, Elizaveta Rebrova\n",
    "#2.\n",
    "\n",
    "#Imports\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import tensorly as tl\n",
    "from tensorly import decomposition\n",
    "from tensorly import random\n",
    "from tensorly.decomposition import parafac\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from scipy.linalg import dft\n",
    "\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ec638b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=[4] #mode 4 tensors\n",
    "\n",
    "#can add multiple rs or target_dims to list to run multiple experiments \n",
    "ns=[10]  \n",
    "rs=[2]    #ranks\n",
    "target_dims=[int(x**2) for x in [40]]   #Target Dimension\n",
    "meases=[\"Gaussian\"] #Set to either \"Gaussian\" or \"Fourier\" \n",
    "\n",
    "#number of trials\n",
    "num_samples=100\n",
    "\n",
    "#store all parameters in a list of tuples\n",
    "params=[(n1,d,r1,t,meas) for n1 in ns for d in ds for t in target_dims for r1 in rs for meas in meases]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "e163c45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns low CP rank r tensor of dimension n\n",
    "\n",
    "def random_low_cp_rank(n,r):\n",
    "    #torch.manual_seed(0)\n",
    "    #np.random.seed(0)\n",
    "    L = []\n",
    "    for i in range(len(n)):\n",
    "        C=np.random.normal(0,1,size=(n[i],r))\n",
    "        L = L + [C]\n",
    "    \n",
    "    X = np.zeros(n)\n",
    "    for i in range(r):\n",
    "        U_r = np.array(L[0])[:,i]\n",
    "        for j in range(1, len(n)):\n",
    "            prod = np.array(L[j])[:,i]\n",
    "            U_r = np.multiply.outer(U_r,prod)\n",
    "        X = X + U_r\n",
    "        \n",
    "    C=tl.tensor(X) #Changing data frame to tensor\n",
    "    C.shape\n",
    "    return C, L\n",
    "\n",
    "\n",
    "### Some errors in this function, why?\n",
    "def random_low_cp_rank_1(n,r): ### Issues with printing; also, source of randomness?\n",
    "    tensor_1 = tl.random.random_cp(shape=n, rank=r)\n",
    "    return tensor_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "7439b3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(X):\n",
    "    x=X\n",
    "    x=x.reshape(-1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "df9b8e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Low rank approximation via tensorly Cp decomposition is used for thresholding\n",
    "\n",
    "def low_rank_approx(tensor,r):    \n",
    "    #torch.manual_seed(0)\n",
    "    factors = parafac(tl.tensor(tensor), rank=r)\n",
    "    answer = tl.cp_to_tensor(factors)\n",
    "    return answer, factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "2d93bd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor, L = random_low_cp_rank((2,5,3),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "950f1264",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l, a= low_rank_approx(tensor,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "1e9b4a25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 6.79951649e-06, -1.72809819e-03, -4.26127787e-04],\n",
       "        [-3.35595196e-05, -5.32636670e-04, -6.41776761e-05],\n",
       "        [ 5.12836221e-05, -3.37954969e-03, -9.17996088e-04],\n",
       "        [ 5.75894849e-07,  5.85431224e-04,  1.41713697e-04],\n",
       "        [ 1.55013106e-05, -2.62579138e-03, -6.46922248e-04]],\n",
       "\n",
       "       [[ 1.84163180e-05,  6.39714216e-03,  1.61351803e-03],\n",
       "        [-2.16399367e-05,  1.79682592e-03,  4.51750745e-04],\n",
       "        [-5.58544190e-04,  1.20493714e-02,  3.33275280e-03],\n",
       "        [ 1.28337180e-04, -2.01561282e-03, -5.70257676e-04],\n",
       "        [ 5.23009620e-04,  1.02554725e-02,  2.35693471e-03]]])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l-tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "896a0da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Measurement operators \n",
    "\n",
    "#SJLT\n",
    "def create_SJLT_meas(dim, n):\n",
    "    #np.random.seed(0)\n",
    "    return np.sqrt(1/dim)*np.random.normal(0.0, 1.0, [dim, n])\n",
    "\n",
    "\n",
    "#Gaussian\n",
    "def create_gaussian_meas(dim, n):\n",
    "    #np.random.seed(0)\n",
    "    return np.sqrt(1/dim)*np.random.normal(0.0, 1.0, [dim, n])\n",
    "\n",
    "#SORS\n",
    "def create_SORS_meas(dim,n):\n",
    "    if n<dim:\n",
    "        raise ValueError(\"dim is greater than n, matrix needs to be tall and skinny\")\n",
    "    \n",
    "    n_prod = 1\n",
    "    for i in n:\n",
    "        n_prod = n_prod*i   \n",
    "        \n",
    "    #np.random.seed(0)\n",
    "    m=dft(n_prod)/np.sqrt(n_prod)\n",
    "    vec=np.random.choice([-1,1],n_prod)\n",
    "    m = np.matmul(m, np.diag(vec))\n",
    "    m = np.sqrt(n_prod/dim)*m[:int(dim), :]\n",
    "    return m  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "be27eebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_error(true,guess,first_loss):\n",
    "    return (np.linalg.norm(true - guess)/first_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2e55f67f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.26150109,  0.43724346,  0.39923038,  0.38642333, -0.37087732,\n",
       "        -0.42779058, -0.05456498, -0.39196885],\n",
       "       [-0.09172095, -0.56882438,  0.68621397, -0.35651651, -0.17617069,\n",
       "        -0.52011357,  0.17653106,  0.48202586],\n",
       "       [ 1.02176363, -0.47327028,  1.01450405,  0.53059328, -0.07395612,\n",
       "        -0.18648097,  0.02381816,  0.19947269],\n",
       "       [ 0.78007322, -0.16755619,  0.29075811,  0.04897233,  0.28792401,\n",
       "         0.05645328,  0.48702222, -0.07107476],\n",
       "       [ 0.37899115, -0.32588092, -0.26222688,  0.47376614, -0.43033831,\n",
       "         0.30894632, -0.05789954, -0.55941463],\n",
       "       [ 1.20212995, -0.58951792, -0.03546118, -0.19355324, -0.33815828,\n",
       "         0.36811499, -0.08015499, -0.27671187]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(1/6)*np.random.normal(0.0, 1.0, [6, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "3f4d9e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Generate Random Tensors\n",
    "def generate_tensors(n,r,num_samples):\n",
    "\n",
    "    #torch.manual_seed(0)\n",
    "    X= []\n",
    "    for j in range(num_samples):\n",
    "        X_i= torch.tensor(random_low_cp_rank(n,r), dtype=torch.float64)\n",
    "        X.append(X_i)\n",
    "        \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7c59f8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorized Measurements\n",
    "def vectorized_measurements(X,dim,num_samples):\n",
    "\n",
    "    #torch.manual_seed(0)\n",
    "    n=tuple(X[0].shape)\n",
    "    n_prod = 1\n",
    "    for i in n:\n",
    "        n_prod = n_prod*i\n",
    "    \n",
    "    yy = []\n",
    "    start = timeit.default_timer()\n",
    "    if meas==\"Fourier\":\n",
    "        Afinal=create_kfjl_meas(dim, n_prod)\n",
    "    elif meas==\"Gaussian\":\n",
    "        Afinal=create_gaussian_meas(dim, n_prod)\n",
    "    else:\n",
    "        raise ValueError(\"Set meas to either 'Fourier' or 'Gaussian'\")\n",
    "    \n",
    "    Afconj = Afinal.conj().T\n",
    "    for j in range(num_samples):\n",
    "        y =  np.matmul(Afinal,vectorize(X[j]))\n",
    "        yy.append(y)\n",
    "    stop = timeit.default_timer()\n",
    "    print(Afinal)\n",
    "    print(y.shape)\n",
    "    print('Measurement time: ', (stop - start)/num_samples)\n",
    "    avg_meas_time=(stop - start)/num_samples\n",
    "    return Afinal,Afconj,yy, avg_meas_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2bb40bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CP-TIHT Algorithm\n",
    "\n",
    "def TIHT(n,r,dim,num_samples=100,mu=.1,N_iter=1000,accuracy=.001):\n",
    "\n",
    "    #torch.manual_seed(0)\n",
    "\n",
    "    X = generate_tensors(n,r,num_samples) #generating 100 tensors\n",
    "    Afinal,Afconj,yy, avg_meas_time=vectorized_measurements(X,dim,num_samples)\n",
    "\n",
    "    Losses3 = [[1] for _ in range(num_samples)]\n",
    "    \n",
    "    good_runs = 0\n",
    "    total_time = 0\n",
    "    total_iters = 0\n",
    "\n",
    "    n=tuple(X[0].shape)\n",
    "\n",
    "    X0 = torch.randn(n)\n",
    "\n",
    "    # Run recovery algorithm\n",
    "    for j in range(num_samples):\n",
    "        #print(j)\n",
    "        start = timeit.default_timer()\n",
    "        X_iter=torch.clone(X0)\n",
    "        first_loss = np.linalg.norm(X[j] - X_iter)\n",
    "        i = 0\n",
    "        while Losses3[j][-1] > accuracy and i < N_iter:\n",
    "            i += 1 \n",
    "            Losses3[j].append(relative_error(true=X[j] ,guess=X_iter, first_loss=first_loss))\n",
    "            measX = np.matmul(Afinal,vectorize(X_iter))\n",
    "            Z = yy[j] - measX\n",
    "     \n",
    "            Z = torch.reshape(torch.tensor(np.matmul(Afconj, Z)), n)\n",
    "            Y_iter= np.array(X_iter)+mu*np.array(Z)\n",
    "    \n",
    "            X_iter=low_rank_approx(Y_iter, r)\n",
    "        stop = timeit.default_timer()\n",
    "    \n",
    "        #plt.plot(range(len(Losses3[j])), Losses3[j])   \n",
    "        if i < N_iter:\n",
    "            good_runs += 1\n",
    "            total_time += stop - start\n",
    "            total_iters += i\n",
    "            #print(\"Converged!\")\n",
    "            #print('Number of iterations: ', i)\n",
    "    '''if good_runs != 0:\n",
    "        print('\\n')\n",
    "        print('Percentage of converged runs:', 100*good_runs/num_samples)\n",
    "        print('Average recovery time: ', total_time/good_runs) \n",
    "        print('Average number of iterations: ', total_iters/good_runs) \n",
    "    else:\n",
    "        print(\"Never converged :(\")'''\n",
    "        \n",
    "    if good_runs != 0:\n",
    "        Convergence_percent=100*good_runs/num_samples\n",
    "        Average_recovery_time= total_time/good_runs\n",
    "        Average_number_of_iterations= total_iters/good_runs \n",
    "   \n",
    "    else:\n",
    "        Convergence_percent=0\n",
    "        Average_recovery_time= np.inf\n",
    "        Average_number_of_iterations= N_iter\n",
    "   \n",
    "    return Convergence_percent, Average_recovery_time, Average_number_of_iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2829b1f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[ 0.35449633,  0.11993349],\n",
       "         [-0.07092101,  0.19813952]],\n",
       " \n",
       "        [[ 0.46661256,  3.24300344],\n",
       "         [ 0.22353638,  1.03969467]]]),\n",
       " array([[[-0.8571351 ,  2.45645279],\n",
       "         [ 0.47169531, -1.28524858]],\n",
       " \n",
       "        [[-0.43872991,  0.9125632 ],\n",
       "         [ 0.62006192, -1.48858708]]]),\n",
       " array([[[-0.71548326,  0.82503068],\n",
       "         [-0.05711954,  0.06038757]],\n",
       " \n",
       "        [[-3.64176973,  4.83045518],\n",
       "         [-0.30838667,  0.68348106]]]),\n",
       " array([[[-0.5351592 ,  0.51296666],\n",
       "         [ 0.1760892 , -0.30951059]],\n",
       " \n",
       "        [[ 0.39345461, -0.91989999],\n",
       "         [-1.54001826, -2.20014139]]])]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = generate_tensors((2,2,2),2,1) #generating 100 tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "b5abe74c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.06005319  1.04013912 -0.83005407 -0.46835473 -0.17545923 -0.06272037\n",
      "  -0.00579962  0.9029238 ]\n",
      " [ 0.62436748 -0.0349792   0.11811999  0.75464745 -0.17349836  0.04115035\n",
      "  -0.08649229 -0.45901935]\n",
      " [-0.63415078 -0.2421735   0.2879426   0.11248248  0.67503637  0.28588326\n",
      "   0.27587621 -0.03133723]\n",
      " [-0.09152512  0.02457839  0.1296615  -0.13301549  0.07336067 -0.1207284\n",
      "   0.04894593 -0.27776161]\n",
      " [ 0.1830972   0.48190246 -0.22924035  0.28540162 -0.11699345  0.09660505\n",
      "   0.21049334  0.17502218]\n",
      " [ 0.16708231 -0.28756904  0.1425399  -0.29922317 -0.44174516 -0.27543545\n",
      "  -0.1061101   0.26893757]\n",
      " [-0.92051604  0.08175615  0.02198367  0.46577936 -0.2086078   0.39269736\n",
      "   0.37061337 -0.10227804]\n",
      " [ 0.07820479 -0.30262484  0.00408653 -0.33010135  0.68808749 -0.75166663\n",
      "   0.10426023  0.44069024]]\n",
      "torch.Size([8])\n",
      "Measurement time:  0.0004159306666527603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1m/d1lrmr2n7gvdmlys8cnm3nt40000gn/T/ipykernel_1852/4146494319.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Z = torch.reshape(torch.tensor(np.matmul(Afconj, Z)), n)\n"
     ]
    }
   ],
   "source": [
    "Convergence_percent, Average_recovery_time, Average_number_of_iterations = TIHT((2,2,2),2,8,num_samples=3,mu=.1,N_iter=1000,accuracy=.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "93d96b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Convergence_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "76f47df6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.2613326  -0.66011954 -0.0099311  -0.30129986  0.11427874 -0.04006973\n",
      "   0.37157898  0.12950379]\n",
      " [ 0.32101705 -0.1904148  -0.38556857 -0.16740209 -0.00694855  0.15478805\n",
      "   0.92235902 -0.01725141]\n",
      " [-0.39026291 -0.14124647 -0.18926226  0.19656399 -0.62902775  0.0258266\n",
      "   0.06389353  0.09478751]\n",
      " [-0.24385326 -0.09713114 -0.58137043 -0.201397   -0.22162227  0.16985172\n",
      "  -0.4720095   0.31892279]\n",
      " [ 0.61012076 -0.84506785  0.1740194   0.27634655 -0.26023258 -0.16218554\n",
      "  -0.05424827 -0.12157262]\n",
      " [-0.12615402 -0.68422569  0.47043739  0.44075244 -0.33205457 -0.59866522\n",
      "   0.21272385 -0.23506445]]\n",
      "(6,)\n",
      "Measurement time:  0.00023126049995880749\n"
     ]
    }
   ],
   "source": [
    "meas = \"Gaussian\"\n",
    "Afinal,Afconj,yy, avg_meas_time=vectorized_measurements(X,6,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "503b28a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=tuple(X[0].shape)\n",
    "\n",
    "X0 = torch.randn(n)\n",
    "Losses3 = [[1] for _ in range(num_samples)]\n",
    "j = 0\n",
    "mu = 0.1\n",
    "r = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "8e11aacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "        start = timeit.default_timer()\n",
    "        X_iter=np.array(torch.clone(X0))\n",
    "        first_loss = np.linalg.norm(X[0] - X_iter)\n",
    "        i = 0\n",
    "        while Losses3[0][-1] > 0.01 and i < 10000:\n",
    "            i += 1 \n",
    "            Losses3[j].append(relative_error(true=X[0] ,guess=X_iter, first_loss=first_loss))\n",
    "            measX = np.matmul(Afinal,vectorize(X_iter))\n",
    "            Z = yy[0] - measX\n",
    "     \n",
    "            Z = torch.reshape(torch.tensor(np.matmul(Afconj, Z)), n)\n",
    "            Y_iter= np.array(X_iter)+mu*np.array(Z)\n",
    "    \n",
    "            X_iter=low_rank_approx(Y_iter, r)\n",
    "        stop = timeit.default_timer()\n",
    "    \n",
    "        #plt.plot(range(len(Losses3[j])), Losses3[j])   \n",
    "        if i < 1000:\n",
    "            good_runs += 1\n",
    "            total_time += stop - start\n",
    "            total_iters += i\n",
    "            print(\"Converged!\")\n",
    "            print('Number of iterations: ', i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "4ccd8e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1.0,\n",
       " 1.0405261818444624,\n",
       " 1.1013831828733711,\n",
       " 1.1662751134918015,\n",
       " 1.228223119519232,\n",
       " 1.2846896050781762,\n",
       " 1.3350971360611248,\n",
       " 1.3796768025718833,\n",
       " 1.418948278127542,\n",
       " 1.4534754329684618,\n",
       " 1.4837920842405852,\n",
       " 1.5104368476042083,\n",
       " 1.533938501294389,\n",
       " 1.5547551420911576,\n",
       " 1.5732496148510464,\n",
       " 1.5897051740619157,\n",
       " 1.604352207972432,\n",
       " 1.6173893066616551,\n",
       " 1.6289945213218204,\n",
       " 1.6393286762921406,\n",
       " 1.6485353104256781,\n",
       " 1.6567409487135836,\n",
       " 1.6640565318922769,\n",
       " 1.6705793294536255,\n",
       " 1.6763947831984178,\n",
       " 1.6815781148613247,\n",
       " 1.686195695658868,\n",
       " 1.6903062102923372,\n",
       " 1.6939616486823739,\n",
       " 1.6972081539914405,\n",
       " 1.700086750559891,\n",
       " 1.702633971077896,\n",
       " 1.7048823987638657,\n",
       " 1.706861137467471,\n",
       " 1.708596220348785,\n",
       " 1.7101109659836697,\n",
       " 1.711426289304007,\n",
       " 1.712560973616241,\n",
       " 1.7135319089897023,\n",
       " 1.7143543015202913,\n",
       " 1.715041857320643,\n",
       " 1.7156069445387139,\n",
       " 1.7160607362432527,\n",
       " 1.7164133366215006,\n",
       " 1.7166738925998497,\n",
       " 1.716850692712447,\n",
       " 1.7169512547981618,\n",
       " 1.7169824038965174,\n",
       " 1.716950341532944,\n",
       " 1.716860707428532,\n",
       " 1.7167186345357786,\n",
       " 1.7165287981863753,\n",
       " 1.716295460037396,\n",
       " 1.7160225074159359,\n",
       " 1.7157134885875192,\n",
       " 1.715371644408758,\n",
       " 1.7149999367684625,\n",
       " 1.714601074172447,\n",
       " 1.7141775347846848,\n",
       " 1.7137315872003365,\n",
       " 1.7132653091937677,\n",
       " 1.712780604656379,\n",
       " 1.7122792189143077,\n",
       " 1.7117627525943662,\n",
       " 1.7112326741875707,\n",
       " 1.7106903314429145,\n",
       " 1.7101369617093443,\n",
       " 1.709573701331,\n",
       " 1.7090015941893437,\n",
       " 1.708421599475788,\n",
       " 1.7078345987695227,\n",
       " 1.707241402487381,\n",
       " 1.7066427557656274,\n",
       " 1.706039343827359,\n",
       " 1.7054317968837278,\n",
       " 1.7048206946123192,\n",
       " 1.7042065702516578,\n",
       " 1.703589914346956,\n",
       " 1.7029711781787549,\n",
       " 1.7023507769030193,\n",
       " 1.7017290924284834,\n",
       " 1.7011064760545775,\n",
       " 1.7004832508910337,\n",
       " 1.6998597140782967,\n",
       " 1.699236138826058,\n",
       " 1.6986127762856338,\n",
       " 1.697989857270462,\n",
       " 1.6973675938376787,\n",
       " 1.6967461807425652,\n",
       " 1.6961257967765941,\n",
       " 1.6955066059988406,\n",
       " 1.694888758869655,\n",
       " 1.6942723932947175,\n",
       " 1.693657635586866,\n",
       " 1.6930446013524663,\n",
       " 1.6924333963084854,\n",
       " 1.691824117035914,\n",
       " 1.6912168516746908,\n",
       " 1.6906116805648534,\n",
       " 1.6900086768382274,\n",
       " 1.6894079069646137,\n",
       " 1.6888094312560933,\n",
       " 1.6882133043327798,\n",
       " 1.6876195755530545,\n",
       " 1.6870282894110915,\n",
       " 1.686439485904228,\n",
       " 1.6858532008725435,\n",
       " 1.6852694663128076,\n",
       " 1.6846883106687875,\n",
       " 1.6841097590997443,\n",
       " 1.6835338337287964,\n",
       " 1.682960553872703,\n",
       " 1.6823899362544874,\n",
       " 1.6818219952002085,\n",
       " 1.6812567428210976,\n",
       " 1.680694189182164,\n",
       " 1.6801343424582942,\n",
       " 1.679577209078797,\n",
       " 1.67902279386126,\n",
       " 1.67847110013552,\n",
       " 1.677922129858492,\n",
       " 1.6773758837205437,\n",
       " 1.6768323612440355,\n",
       " 1.676291560874625,\n",
       " 1.6757534800658593,\n",
       " 1.6752181153575674,\n",
       " 1.6746854624484953,\n",
       " 1.6741555162636266,\n",
       " 1.6736282710165682,\n",
       " 1.673103720267368,\n",
       " 1.672581856976105,\n",
       " 1.6720626709125488,\n",
       " 1.671546159248969,\n",
       " 1.6710323085263856,\n",
       " 1.6705211122062464,\n",
       " 1.6700125609419352,\n",
       " 1.6695066428664904,\n",
       " 1.6690033453064317,\n",
       " 1.6685026603681372,\n",
       " 1.6680045854176846,\n",
       " 1.667509099845131,\n",
       " 1.6670161997616924,\n",
       " 1.6665258668686636,\n",
       " 1.6660380946153377,\n",
       " 1.6655528689585517,\n",
       " 1.665070183123675,\n",
       " 1.6645900206313675,\n",
       " 1.6641123738278352,\n",
       " 1.6636372243819362,\n",
       " 1.6631645562516537,\n",
       " 1.6626943688354687,\n",
       " 1.662226649219478,\n",
       " 1.6617613803082152,\n",
       " 1.6612985468470438,\n",
       " 1.6608381419121563,\n",
       " 1.6603801555430966,\n",
       " 1.6599245646726268,\n",
       " 1.6594713727883472,\n",
       " 1.659020549326331,\n",
       " 1.6585720979766343,\n",
       " 1.658125995401784,\n",
       " 1.6576822345224054,\n",
       " 1.6572408000882806,\n",
       " 1.6568016826391645,\n",
       " 1.6563648761938254,\n",
       " 1.6559303528360219,\n",
       " 1.6554981118926135,\n",
       " 1.655068138386871,\n",
       " 1.6546404177877725,\n",
       " 1.6542149401835675,\n",
       " 1.653791693369566,\n",
       " 1.6533706630382217,\n",
       " 1.6529518393288585,\n",
       " 1.6525352079823739,\n",
       " 1.6521207540495877,\n",
       " 1.6517084738216896,\n",
       " 1.651298343711138,\n",
       " 1.650890367290666,\n",
       " 1.6504845264587658,\n",
       " 1.650080806998284,\n",
       " 1.649679197059182,\n",
       " 1.6492796903455793,\n",
       " 1.6488822674584198,\n",
       " 1.648486915519028,\n",
       " 1.6480936336956953,\n",
       " 1.6477024097093038,\n",
       " 1.6473132292864896,\n",
       " 1.646926081063285,\n",
       " 1.6465409514975478,\n",
       " 1.6461578292381953,\n",
       " 1.645776705803088,\n",
       " 1.6453975675073522,\n",
       " 1.6450204061219893,\n",
       " 1.644645207953499,\n",
       " 1.6442719650341184,\n",
       " 1.6439006665465177,\n",
       " 1.6435313039814472,\n",
       " 1.6431638620729736,\n",
       " 1.6427983299904636,\n",
       " 1.6424346969717134,\n",
       " 1.6420729523095405,\n",
       " 1.6417130916393177,\n",
       " 1.641355105596002,\n",
       " 1.6409989701456273,\n",
       " 1.6406446876937946,\n",
       " 1.6402922423550093,\n",
       " 1.6399416237355995,\n",
       " 1.6395928214863562,\n",
       " 1.6392458324623262,\n",
       " 1.638900640204434,\n",
       " 1.638557234482161,\n",
       " 1.638215615003317,\n",
       " 1.6378757631294298,\n",
       " 1.6375376740080765,\n",
       " 1.6372013331774184,\n",
       " 1.6368667276385127,\n",
       " 1.6365338501601052,\n",
       " 1.6362027010180225,\n",
       " 1.635873258649717,\n",
       " 1.6355455225016158,\n",
       " 1.6352194800629327,\n",
       " 1.6348951219437695,\n",
       " 1.634572436396405,\n",
       " 1.6342514167151088,\n",
       " 1.633932047843352,\n",
       " 1.6336143268674854,\n",
       " 1.6332982475962226,\n",
       " 1.6329837952949942,\n",
       " 1.632670956801765,\n",
       " 1.6323597371747791,\n",
       " 1.632050120603716,\n",
       " 1.6317421002658958,\n",
       " 1.631435660798557,\n",
       " 1.6311307916854902,\n",
       " 1.630827502125796,\n",
       " 1.6305257668766764,\n",
       " 1.6302255800879752,\n",
       " 1.629926935697154,\n",
       " 1.6296298226645394,\n",
       " 1.6293342322597675,\n",
       " 1.6290401644475085,\n",
       " 1.6287476033715953,\n",
       " 1.6284565464997014,\n",
       " 1.628166976128515,\n",
       " 1.6278788872713306,\n",
       " 1.6275922714534647,\n",
       " 1.6273071272597952,\n",
       " 1.6270234433587647,\n",
       " 1.6267412117216815,\n",
       " 1.6264604217840204,\n",
       " 1.6261810683479163,\n",
       " 1.6259031435397489,\n",
       " 1.6256266367983023,\n",
       " 1.6253515432204764,\n",
       " 1.625077855071701,\n",
       " 1.6248055668932195,\n",
       " 1.6245346603098987,\n",
       " 1.62426513652159,\n",
       " 1.623996993481309,\n",
       " 1.6237302127126163,\n",
       " 1.6234647921469054,\n",
       " 1.6232007210369062,\n",
       " 1.6229379986088595,\n",
       " 1.622676611282487,\n",
       " 1.6224165548177434,\n",
       " 1.622157821933617,\n",
       " 1.621900405379043,\n",
       " 1.6216442949659755,\n",
       " 1.6213894866802272,\n",
       " 1.6211359699729506,\n",
       " 1.6208837446556443,\n",
       " 1.6206328002680952,\n",
       " 1.6203831269191107,\n",
       " 1.6201347233554235,\n",
       " 1.6198875772702472,\n",
       " 1.6196416813027594,\n",
       " 1.6193970319495763,\n",
       " 1.6191536252076053,\n",
       " 1.6189114513614855,\n",
       " 1.6186705036512523,\n",
       " 1.618430769985823,\n",
       " 1.6181922455664044,\n",
       " 1.6179549315400985,\n",
       " 1.6177188141106091,\n",
       " 1.6174838903559243,\n",
       " 1.6172501537879787,\n",
       " 1.6170176007883428,\n",
       " 1.6167862191966835,\n",
       " 1.6165560054248547,\n",
       " 1.6163269531053348,\n",
       " 1.6160990488222893,\n",
       " 1.6158723004623154,\n",
       " 1.6156466947479196,\n",
       " 1.6154222229085118,\n",
       " 1.6151988813970344,\n",
       " 1.6149766610563452,\n",
       " 1.614755563884818,\n",
       " 1.6145355739904879,\n",
       " 1.6143166867820389,\n",
       " 1.614098907167158,\n",
       " 1.6138822146665377,\n",
       " 1.613666610528286,\n",
       " 1.613452093466376,\n",
       " 1.613238648472114,\n",
       " 1.6130262742072052,\n",
       " 1.6128149648841335,\n",
       " 1.6126047147367886,\n",
       " 1.6123955154340914,\n",
       " 1.6121873664114164,\n",
       " 1.6119802572493178,\n",
       " 1.6117741846392803,\n",
       " 1.6115691403614856,\n",
       " 1.6113651257587964,\n",
       " 1.611162133531153,\n",
       " 1.6109601468799677,\n",
       " 1.6107591747499928,\n",
       " 1.6105592048581274,\n",
       " 1.6103602360168026,\n",
       " 1.6101622539815228,\n",
       " 1.6099652623369882,\n",
       " 1.6097692511210784,\n",
       " 1.6095742154945647,\n",
       " 1.609380151925977,\n",
       " 1.6091870546129856,\n",
       " 1.6089949183514967,\n",
       " 1.6088037379662041,\n",
       " 1.6086135085391473,\n",
       " 1.6084242245809048,\n",
       " 1.6082358810967512,\n",
       " 1.6080484708957363,\n",
       " 1.6078619932508154,\n",
       " 1.607676437489084,\n",
       " 1.6074918071038555,\n",
       " 1.6073080919687097,\n",
       " 1.6071252872398476,\n",
       " 1.6069433880882265,\n",
       " 1.606762386161202,\n",
       " 1.606582280754047,\n",
       " 1.6064030711842123,\n",
       " 1.6062247430215066,\n",
       " 1.606047296965105,\n",
       " 1.6058707281791615,\n",
       " 1.6056950343613703,\n",
       " 1.6055202033154312,\n",
       " 1.6053462357460002,\n",
       " 1.6051731268974128,\n",
       " 1.6050008720725686,\n",
       " 1.6048294691772533,\n",
       " 1.6046589106923106,\n",
       " 1.6044891892801092,\n",
       " 1.6043202998485104,\n",
       " 1.6041522465600908,\n",
       " 1.6039850199930705,\n",
       " 1.6038186095617644,\n",
       " 1.6036530216395437,\n",
       " 1.6034882474169492,\n",
       " 1.6033242770834495,\n",
       " 1.603161118256147,\n",
       " 1.6029987598496145,\n",
       " 1.6028371948778013,\n",
       " 1.6026764184922246,\n",
       " 1.6025164307794773,\n",
       " 1.6023572315741044,\n",
       " 1.602198807245812,\n",
       " 1.6020411587990437,\n",
       " 1.6018842840854546,\n",
       " 1.6017281742486063,\n",
       " 1.6015728300926657,\n",
       " 1.6014182447909253,\n",
       " 1.6012644117706067,\n",
       " 1.6011113300059825,\n",
       " 1.6009589954318506,\n",
       " 1.6008074069710734,\n",
       " 1.6006565517831666,\n",
       " 1.6005064323269664,\n",
       " 1.6003570505112772,\n",
       " 1.6002083892125203,\n",
       " 1.600060449796063,\n",
       " 1.5999132308044965,\n",
       " 1.5997667306008512,\n",
       " 1.5996209355981363,\n",
       " 1.5994758572721857,\n",
       " 1.5993314804847905,\n",
       " 1.599187802540039,\n",
       " 1.5990448244430788,\n",
       " 1.5989025397444632,\n",
       " 1.5987609423064135,\n",
       " 1.5986200293670172,\n",
       " 1.5984797995107862,\n",
       " 1.5983402489729521,\n",
       " 1.5982013740417924,\n",
       " 1.5980631764159998,\n",
       " 1.5979256405903906,\n",
       " 1.597788772294884,\n",
       " 1.5976525649376299,\n",
       " 1.5975170123026692,\n",
       " 1.5973821170482247,\n",
       " 1.5972478651528668,\n",
       " 1.5971142634854454,\n",
       " 1.5969813042058052,\n",
       " 1.5968489907570396,\n",
       " 1.5967173092697315,\n",
       " 1.596586267167309,\n",
       " 1.5964558498062071,\n",
       " 1.596326058254622,\n",
       " 1.5961968932093997,\n",
       " 1.5960683453053734,\n",
       " 1.5959404218583555,\n",
       " 1.5958131153456119,\n",
       " 1.5956864097246641,\n",
       " 1.5955603147498942,\n",
       " 1.5954348242738312,\n",
       " 1.5953099325668254,\n",
       " 1.595185642028628,\n",
       " 1.595061943595504,\n",
       " 1.5949388373636972,\n",
       " 1.594816317834613,\n",
       " 1.5946943845613446,\n",
       " 1.5945730323665503,\n",
       " 1.5944522623943738,\n",
       " 1.5943320716432112,\n",
       " 1.594212451184078,\n",
       " 1.5940934013259,\n",
       " 1.5939749190193973,\n",
       " 1.593856998863709,\n",
       " 1.5937396387616158,\n",
       " 1.5936228340621472,\n",
       " 1.5935065904274988,\n",
       " 1.5933908997524986,\n",
       " 1.5932757572828125,\n",
       " 1.593161166380346,\n",
       " 1.5930471166855837,\n",
       " 1.5929336035083252,\n",
       " 1.592820634719435,\n",
       " 1.5927081992030274,\n",
       " 1.5925962967198979,\n",
       " 1.592484924422754,\n",
       " 1.5923740846550065,\n",
       " 1.5922637654489056,\n",
       " 1.5921539654024324,\n",
       " 1.5920446872927383,\n",
       " 1.5919359285085564,\n",
       " 1.591827676547705,\n",
       " 1.5917199361659102,\n",
       " 1.5916127023105404,\n",
       " 1.5915059773377602,\n",
       " 1.5913997512498774,\n",
       " 1.5912940311511328,\n",
       " 1.5911888087764643,\n",
       " 1.591084078950584,\n",
       " 1.590979840133134,\n",
       " 1.590876097308536,\n",
       " 1.5907728388229936,\n",
       " 1.5906700656976558,\n",
       " 1.590567772931097,\n",
       " 1.5904659609329275,\n",
       " 1.5903646270625404,\n",
       " 1.5902637713492715,\n",
       " 1.590163378756248,\n",
       " 1.5900634627324877,\n",
       " 1.5899640200609382,\n",
       " 1.5898650366574483,\n",
       " 1.5897665191611274,\n",
       " 1.5896684596006316,\n",
       " 1.5895708612149138,\n",
       " 1.5894737157971959,\n",
       " 1.5893770242453837,\n",
       " 1.5892807818911734,\n",
       " 1.589184994182553,\n",
       " 1.589089645228183,\n",
       " 1.588994741630273,\n",
       " 1.5889002853160479,\n",
       " 1.5888062637125444,\n",
       " 1.5887126823714317,\n",
       " 1.5886195362597983,\n",
       " 1.58852682310184,\n",
       " 1.5884345383804583,\n",
       " 1.5883426877928295,\n",
       " 1.5882512574024008,\n",
       " 1.5881602496900329,\n",
       " 1.58806966929937,\n",
       " 1.5879795036702793,\n",
       " 1.587889756414699,\n",
       " 1.587800430016277,\n",
       " 1.587711509493881,\n",
       " 1.5876230030810248,\n",
       " 1.5875349061170085,\n",
       " 1.5874472216467146,\n",
       " 1.587359938073091,\n",
       " 1.5872730526908192,\n",
       " 1.5871865711192035,\n",
       " 1.5871004863966416,\n",
       " 1.5870147990525925,\n",
       " 1.5869295068968827,\n",
       " 1.5868446077837308,\n",
       " 1.5867600996052076,\n",
       " 1.5866759802859993,\n",
       " 1.5865922477791894,\n",
       " 1.5865088963922662,\n",
       " 1.586425930402606,\n",
       " 1.586343345516131,\n",
       " 1.586261141832834,\n",
       " 1.5861793146889214,\n",
       " 1.5860978581840124,\n",
       " 1.586016777387862,\n",
       " 1.5859360659862445,\n",
       " 1.5858557228296397,\n",
       " 1.5857757515267477,\n",
       " 1.5856961434804442,\n",
       " 1.5856168993998336,\n",
       " 1.5855380219574624,\n",
       " 1.585459498812728,\n",
       " 1.5853813342274992,\n",
       " 1.5853035244727773,\n",
       " 1.5852260718222493,\n",
       " 1.5851489685286906,\n",
       " 1.5850722187362642,\n",
       " 1.5849958204008545,\n",
       " 1.5849197716036445,\n",
       " 1.5848440651933315,\n",
       " 1.5847687006107338,\n",
       " 1.5846936808076664,\n",
       " 1.5846190038556502,\n",
       " 1.5845446600964268,\n",
       " 1.5844706561908186,\n",
       " 1.5843969834487437,\n",
       " 1.5843236453696772,\n",
       " 1.5842506419713438,\n",
       " 1.584177971312951,\n",
       " 1.5841056263748519,\n",
       " 1.5840336049379153,\n",
       " 1.583961913725907,\n",
       " 1.5838905440350497,\n",
       " 1.5838194989852732,\n",
       " 1.5837487720510988,\n",
       " 1.5836783643725332,\n",
       " 1.5836082742560766,\n",
       " 1.5835385000360516,\n",
       " 1.5834690366005109,\n",
       " 1.5833998902683748,\n",
       " 1.583331054746717,\n",
       " 1.5832625284934805,\n",
       " 1.58319431236176,\n",
       " 1.5831263973263867,\n",
       " 1.583058787688603,\n",
       " 1.582991483866941,\n",
       " 1.5829244794584207,\n",
       " 1.582857773896653,\n",
       " 1.5827913718665252,\n",
       " 1.5827252643919931,\n",
       " 1.5826594510279959,\n",
       " 1.5825939345249325,\n",
       " 1.5825287108330246,\n",
       " 1.5824637784813984,\n",
       " 1.5823991310068573,\n",
       " 1.582334778445573,\n",
       " 1.5822707088390735,\n",
       " 1.5822069293409922,\n",
       " 1.5821434282671385,\n",
       " 1.5820802142927768,\n",
       " 1.5820172816023865,\n",
       " 1.5819546287977047,\n",
       " 1.5818922566571336,\n",
       " 1.5818301610097087,\n",
       " 1.5817683406188556,\n",
       " 1.581706791985959,\n",
       " 1.581645519006008,\n",
       " 1.5815845131059814,\n",
       " 1.5815237784865686,\n",
       " 1.5814633136177862,\n",
       " 1.581403117014887,\n",
       " 1.5813431892518852,\n",
       " 1.5812835225368043,\n",
       " 1.581224120477203,\n",
       " 1.581164981572035,\n",
       " 1.5811061061458336,\n",
       " 1.5810474926120814,\n",
       " 1.5809891369399771,\n",
       " 1.5809310380027013,\n",
       " 1.5808731890317458,\n",
       " 1.5808155996104585,\n",
       " 1.580758261823642,\n",
       " 1.5807011768789638,\n",
       " 1.5806443453444323,\n",
       " 1.5805877597757225,\n",
       " 1.5805314253357157,\n",
       " 1.5804753367615432,\n",
       " 1.5804194966760154,\n",
       " 1.5803639035436252,\n",
       " 1.5803085514665942,\n",
       " 1.5802534402978194,\n",
       " 1.5801985774166245,\n",
       " 1.5801439486700983,\n",
       " 1.5800895613088017,\n",
       " 1.5800354091910327,\n",
       " 1.5799814940496488,\n",
       " 1.5799278168485817,\n",
       " 1.579874371333684,\n",
       " 1.5798211574629888,\n",
       " 1.5797681806338812,\n",
       " 1.5797154341301134,\n",
       " 1.5796629127529327,\n",
       " 1.5796106229486064,\n",
       " 1.5795585572355757,\n",
       " 1.5795067209078868,\n",
       " 1.5794551087114928,\n",
       " 1.579403723374046,\n",
       " 1.5793525634052485,\n",
       " 1.5793016250197078,\n",
       " 1.5792509034345887,\n",
       " 1.5792004044261772,\n",
       " 1.5791501265196124,\n",
       " 1.579100063760145,\n",
       " 1.57905021617959,\n",
       " 1.5790005890135381,\n",
       " 1.5789511736871387,\n",
       " 1.5789019721447122,\n",
       " 1.5788529814596255,\n",
       " 1.578804203026993,\n",
       " 1.5787556356759782,\n",
       " 1.5787072782705696,\n",
       " 1.5786591297038675,\n",
       " 1.5786111888935077,\n",
       " 1.5785634547779788,\n",
       " 1.5785159263136521,\n",
       " 1.5784686044430072,\n",
       " 1.5784214804467207,\n",
       " 1.5783745653374297,\n",
       " 1.5783278510885559,\n",
       " 1.5782813368793807,\n",
       " 1.5782350180954046,\n",
       " 1.5781888988634571,\n",
       " 1.5781429780438894,\n",
       " 1.5780972563063387,\n",
       " 1.5780517284681468,\n",
       " 1.5780063959761101,\n",
       " 1.5779612577945936,\n",
       " 1.5779163129133222,\n",
       " 1.5778715643125198,\n",
       " 1.5778270035995974,\n",
       " 1.577782635136166,\n",
       " 1.577738449550503,\n",
       " 1.5776944535953934,\n",
       " 1.5776506477232997,\n",
       " 1.5776070306034367,\n",
       " 1.5775635987850383,\n",
       " 1.5775203514823744,\n",
       " 1.577477284331389,\n",
       " 1.5774344048488602,\n",
       " 1.5773917071879406,\n",
       " 1.5773491869520972,\n",
       " 1.577306845538285,\n",
       " 1.577264689761448,\n",
       " 1.5772227109244017,\n",
       " 1.5771809104705639,\n",
       " 1.5771392874577366,\n",
       " 1.5770978447121677,\n",
       " 1.5770565725740404,\n",
       " 1.5770154772037985,\n",
       " 1.576974555354877,\n",
       " 1.5769338044983332,\n",
       " 1.5768932279785306,\n",
       " 1.5768528225236995,\n",
       " 1.5768125840703349,\n",
       " 1.576772519610617,\n",
       " 1.5767326218817854,\n",
       " 1.5766928943923486,\n",
       " 1.5766533320327933,\n",
       " 1.5766139383619213,\n",
       " 1.576574710072757,\n",
       " 1.5765356464643367,\n",
       " 1.5764967468248479,\n",
       " 1.5764580085712283,\n",
       " 1.5764194375416551,\n",
       " 1.576381025210421,\n",
       " 1.5763427739943496,\n",
       " 1.5763046831496645,\n",
       " 1.5762667500296526,\n",
       " 1.5762289783661771,\n",
       " 1.5761913611449228,\n",
       " 1.576153902447767,\n",
       " 1.576116599881989,\n",
       " 1.5760794575009809,\n",
       " 1.5760424701639892,\n",
       " 1.5760056371658073,\n",
       " 1.5759689561195387,\n",
       " 1.5759324302752218,\n",
       " 1.5758960533824453,\n",
       " 1.5758598304586424,\n",
       " 1.5758237603327008,\n",
       " 1.5757878399384022,\n",
       " 1.5757520669392302,\n",
       " 1.5757164447596097,\n",
       " 1.5756809702981749,\n",
       " 1.5756456397095175,\n",
       " 1.5756104599708258,\n",
       " 1.575575427870204,\n",
       " 1.5755405400467817,\n",
       " 1.5755057939925365,\n",
       " 1.575471190244189,\n",
       " 1.5754367305225294,\n",
       " 1.5754024158028235,\n",
       " 1.5753682449849777,\n",
       " 1.575334210727443,\n",
       " 1.575300317852995,\n",
       " 1.5752665694887922,\n",
       " 1.5752329556244102,\n",
       " 1.5751994829824596,\n",
       " 1.5751661449316463,\n",
       " 1.5751329488611487,\n",
       " 1.5750998892865804,\n",
       " 1.5750669656514007,\n",
       " 1.57503417554018,\n",
       " 1.5750015193002316,\n",
       " 1.5749689999503922,\n",
       " 1.5749366129027436,\n",
       " 1.5749043596675554,\n",
       " 1.5748722410764524,\n",
       " 1.5748402560870456,\n",
       " 1.5748083996724047,\n",
       " 1.5747766723452903,\n",
       " 1.5747450773204605,\n",
       " 1.5747136135520843,\n",
       " 1.5746822759685115,\n",
       " 1.574651066743162,\n",
       " 1.5746199852711658,\n",
       " 1.5745890328757526,\n",
       " 1.574558202769014,\n",
       " 1.574527499396478,\n",
       " 1.5744969256079646,\n",
       " 1.574466475789478,\n",
       " 1.574436147605973,\n",
       " 1.5744059416216107,\n",
       " 1.574375858080053,\n",
       " 1.5743458982147271,\n",
       " 1.5743160626597024,\n",
       " 1.5742863472406852,\n",
       " 1.5742567584495564,\n",
       " 1.5742272822201036,\n",
       " 1.5741979314142347,\n",
       " 1.5741686974790938,\n",
       " 1.5741395860318776,\n",
       " 1.5741105877362074,\n",
       " 1.5740817074064626,\n",
       " 1.5740529429584649,\n",
       " 1.574024295816246,\n",
       " 1.5739957704958092,\n",
       " 1.5739673571705024,\n",
       " 1.5739390583991866,\n",
       " 1.5739108720181485,\n",
       " 1.573882799964814,\n",
       " 1.5738548454150136,\n",
       " 1.5738269973337147,\n",
       " 1.5737992627154322,\n",
       " 1.5737716408260263,\n",
       " 1.5737441342386416,\n",
       " 1.5737167378230974,\n",
       " 1.5736894479584085,\n",
       " 1.5736622702832967,\n",
       " 1.5736352005323433,\n",
       " 1.5736082418059334,\n",
       " 1.5735813898658184,\n",
       " 1.573554647861075,\n",
       " 1.5735280130954552,\n",
       " 1.573501486906373,\n",
       " 1.5734750630697374,\n",
       " 1.5734487458534863,\n",
       " 1.5734225379749933,\n",
       " 1.5733964309283457,\n",
       " 1.573370430573629,\n",
       " 1.573344532645739,\n",
       " 1.573318738838715,\n",
       " 1.5732930501327134,\n",
       " 1.5732674656512444,\n",
       " 1.5732419778026052,\n",
       " 1.5732165957138224,\n",
       " 1.573191314703983,\n",
       " 1.5731661343784844,\n",
       " 1.5731410527711016,\n",
       " 1.5731160716328063,\n",
       " 1.573091190417101,\n",
       " 1.5730664085996335,\n",
       " 1.573041727246039,\n",
       " 1.5730171455242328,\n",
       " 1.572992654627288,\n",
       " 1.5729682666481766,\n",
       " 1.5729439735871447,\n",
       " 1.5729197807183857,\n",
       " 1.572895679383994,\n",
       " 1.5728716775840723,\n",
       " 1.5728477681950919,\n",
       " 1.572823951985463,\n",
       " 1.5728002293895853,\n",
       " 1.5727766065783158,\n",
       " 1.5727530727894834,\n",
       " 1.5727296342341732,\n",
       " 1.572706290043431,\n",
       " 1.5726830354162997,\n",
       " 1.5726598727354215,\n",
       " 1.572636803466137,\n",
       " 1.5726138227473438,\n",
       " 1.5725909313305144,\n",
       " 1.5725681326269738,\n",
       " 1.5725454196616655,\n",
       " 1.5725228004299276,\n",
       " 1.5725002706050573,\n",
       " 1.5724778313452934,\n",
       " 1.5724554799636115,\n",
       " 1.572433213164236,\n",
       " 1.5724110378334957,\n",
       " 1.5723889461904639,\n",
       " 1.5723669421492423,\n",
       " 1.5723450251509767,\n",
       " 1.57232319467363,\n",
       " 1.5723014502252661,\n",
       " 1.5722797927362875,\n",
       " 1.5722582184132123,\n",
       " 1.5722367288982262,\n",
       " 1.5722153237516119,\n",
       " 1.572194002549996,\n",
       " 1.5721727662865896,\n",
       " 1.5721516126052906,\n",
       " 1.5721305386277655,\n",
       " 1.572109550333202,\n",
       " 1.5720886470901985,\n",
       " 1.572067820147801,\n",
       " 1.572047074493816,\n",
       " 1.572026408369227,\n",
       " 1.5720058248070483,\n",
       " 1.5719853187402095,\n",
       " 1.5719648961437152,\n",
       " 1.5719445513760555,\n",
       " 1.5719242875468407,\n",
       " 1.5719041058230436,\n",
       " 1.5718839990303268,\n",
       " 1.5718639668160062,\n",
       " 1.5718440146768788,\n",
       " 1.5718241436928069,\n",
       " 1.5718043435322575,\n",
       " 1.5717846225788172,\n",
       " 1.5717649783177354,\n",
       " 1.5717454103882305,\n",
       " 1.5717259170153066,\n",
       " 1.5717065012663172,\n",
       " 1.5716871623337132,\n",
       " 1.57166789450489,\n",
       " 1.57164870193312,\n",
       " 1.5716295855732645,\n",
       " 1.5716105446449198,\n",
       " 1.571591573450593,\n",
       " 1.5715726776030137,\n",
       " 1.5715538532215498,\n",
       " 1.5715351051021378,\n",
       " 1.571516426822443,\n",
       " 1.5714978205914805,\n",
       " 1.5714792861014129,\n",
       " 1.5714608230458673,\n",
       " 1.5714424327827792,\n",
       " 1.5714241110076577,\n",
       " 1.5714058599072365,\n",
       " 1.571387679151494,\n",
       " 1.5713695684173996,\n",
       " 1.5713515273877936,\n",
       " 1.5713335557505033,\n",
       " 1.571315653197646,\n",
       " 1.5712978194250704,\n",
       " 1.5712800514662961,\n",
       " 1.5712623554431182,\n",
       " 1.571244727062964,\n",
       " 1.5712271660801322,\n",
       " 1.5712096708076928,\n",
       " 1.5711922444438906,\n",
       " 1.5711748845743532,\n",
       " 1.571157590960044,\n",
       " 1.5711403650240612,\n",
       " 1.5711232041613048,\n",
       " 1.5711061065993788,\n",
       " 1.571089073122048,\n",
       " 1.571072106877247,\n",
       " 1.5710552054010194,\n",
       " 1.5710383700907098,\n",
       " 1.57102159831641,\n",
       " 1.5710048899606135,\n",
       " 1.5709882417696406,\n",
       " 1.570971663014641,\n",
       " 1.5709551424739547,\n",
       " 1.5709386852863658,\n",
       " 1.5709222884213736,\n",
       " 1.57090595799342,\n",
       " 1.5708896896533673,\n",
       " 1.5708734848101684,\n",
       " 1.5708573377301782,\n",
       " 1.5708412527053797,\n",
       " 1.5708252307521542,\n",
       " 1.5708092694480091,\n",
       " 1.5707933685644493,\n",
       " 1.5707775295405115,\n",
       " 1.5707617466659773,\n",
       " 1.5707460256982553,\n",
       " 1.570730364199498,\n",
       " 1.5707147619318744,\n",
       " 1.570699220327802,\n",
       " 1.5706837336719537,\n",
       " 1.5706683077227153,\n",
       " 1.570652940039725,\n",
       " 1.5706376289484598,\n",
       " 1.5706223762492697,\n",
       " 1.5706071815712102,\n",
       " 1.570592043333732,\n",
       " 1.5705769629671975,\n",
       " 1.57056194005093,\n",
       " 1.5705469742011848,\n",
       " 1.5705320662999505,\n",
       " 1.5705172142643387,\n",
       " 1.5705024179012022,\n",
       " 1.5704876784474593,\n",
       " 1.5704729936606243,\n",
       " 1.570458362033161,\n",
       " 1.5704437886073477,\n",
       " 1.5704292670468283,\n",
       " 1.5704147997630187,\n",
       " 1.5704003851551327,\n",
       " 1.5703860238522924,\n",
       " 1.57037172162479,\n",
       " 1.5703574702257788,\n",
       " 1.5703432720569792,\n",
       " 1.5703291255111893,\n",
       " 1.5703150338790575,\n",
       " 1.5703009947980235,\n",
       " 1.5702870066686447,\n",
       " 1.5702730701219347,\n",
       " 1.570259186593885,\n",
       " 1.5702453583341636,\n",
       " 1.57023158117556,\n",
       " 1.5702178523655532,\n",
       " 1.5702041755837846,\n",
       " 1.570190551677955,\n",
       " 1.5701769785459705,\n",
       " 1.5701634547540317,\n",
       " 1.5701499818522038,\n",
       " 1.5701365621797203,\n",
       " 1.5701231916495397,\n",
       " 1.5701098702371228,\n",
       " 1.5700965978844583,\n",
       " 1.5700833730789434,\n",
       " 1.570070199178329,\n",
       " 1.570057072459359,\n",
       " 1.5700439948471385,\n",
       " 1.570030967504391,\n",
       " 1.5700179867194217,\n",
       " 1.5700050558501917,\n",
       " 1.5699921726048693,\n",
       " 1.5699793342252724,\n",
       " 1.5699665455979168,\n",
       " 1.5699538045819388,\n",
       " 1.5699411140206654,\n",
       " 1.569928464990171,\n",
       " 1.5699158649372897,\n",
       " 1.5699033117260415,\n",
       " 1.5698908065475856,\n",
       " 1.569878347147889,\n",
       " 1.5698659320283832,\n",
       " 1.569853563122387,\n",
       " 1.5698412432485813,\n",
       " 1.5698289647091315,\n",
       " 1.5698167307423139,\n",
       " 1.5698045440401316,\n",
       " 1.5697924024820533,\n",
       " 1.569780305849356,\n",
       " 1.569768255348117,\n",
       " 1.569756248745641,\n",
       " 1.5697442845640641,\n",
       " 1.569732363529274,\n",
       " 1.5697204883647367,\n",
       " 1.5697086569833547,\n",
       " 1.5696968706065142,\n",
       " 1.5696851256066189,\n",
       " 1.5696734253736557,\n",
       " 1.5696617693155708,\n",
       " 1.5696501519630262,\n",
       " 1.5696385791780392,\n",
       " 1.5696270472582292,\n",
       " 1.5696155558571827,\n",
       " 1.5696041089961725,\n",
       " 1.5695927073390263,\n",
       " 1.5695813484598766,\n",
       " 1.5695700299892574,\n",
       " 1.5695587520378491,\n",
       " 1.5695475146633013,\n",
       " 1.5695363178805704,\n",
       " 1.5695251574212954,\n",
       " 1.569514041952192,\n",
       " 1.569502967235998,\n",
       " 1.569491930494008,\n",
       " 1.5694809395537546,\n",
       " 1.5694699862718657,\n",
       " 1.5694590730351257,\n",
       " 1.5694481996893699,\n",
       " 1.5694373660796335,\n",
       " ...]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Losses3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f82fc81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros([4,2,3,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f10da7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Attempt TIHT for Cp ranks\n",
    "\n",
    "## Rank"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
