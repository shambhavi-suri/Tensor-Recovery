{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "317eea5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proj_omega(y,x_1,x_2):\n",
    "    e_1 = x_1/np.linalg.norm(x_1)\n",
    "    e_2 = x_2 - (x_2.T@e_1)*e_1\n",
    "    e_2 = e_2/np.linalg.norm(e_2)\n",
    "    \n",
    "    y_proj_1 = (y.T@e_1)*e_1\n",
    "    y_proj_2 = (y.T@e_2)*e_2\n",
    "    \n",
    "    return y_proj_1 + y_proj_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1997e37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proj_vals(A,b,x_it,itr = 250,gamma = 1):\n",
    "    \n",
    "    error = np.zeros(itr)\n",
    "    m = np.shape(A)[0]\n",
    "    \n",
    "    n = np.shape(X)\n",
    "    \n",
    "    proj = []\n",
    "    \n",
    "    for j in range(m): #Inner iteration for Kaczmarz updates\n",
    "        a = A[j,:]\n",
    "        proj_val = np.abs(b[j] - a@x_it)/np.linalg.norm(a)\n",
    "        proj = proj + [proj_val]\n",
    "    \n",
    "    return proj\n",
    "\n",
    "\n",
    "def high_proj(a, number = 5):\n",
    "\n",
    "    res = sorted(range(len(a)), key = lambda sub: a[sub])[-number:]\n",
    "    return res\n",
    "\n",
    "def low_proj(a, number = 5):\n",
    "    res = sorted(range(len(a)), key = lambda sub: a[sub])[:number]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5632bfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TIHT_HOSVD_proj_high(AA,yy,X,r,lamda = 1, itr = 100, num = 4): \n",
    "    \n",
    "    n = np.shape(X)\n",
    "    X_ravel = np.ravel(X)\n",
    "    \n",
    "    error = np.zeros(itr)\n",
    "    \n",
    "    vXX = torch.randn(n)*0\n",
    "\n",
    "    for j in range(itr):\n",
    "        \n",
    "        proj = proj_vals(AA,yy,np.array(vectorize_tl(vXX)))\n",
    "                           \n",
    "        remove_row = high_proj(proj, number = num)\n",
    "        A_1 = np.delete(AA,remove_row,axis = 0)\n",
    "        y_1 = np.delete(yy,remove_row,axis = 0)\n",
    "    \n",
    "        WW = np.array(vectorize_tl(vXX)) + (m/(m-num))*lamda* np.matmul(A_1.T, (y_1 - np.matmul(A_1, np.array(vectorize_tl(vXX)))))\n",
    "        WW = torch.reshape(torch.tensor(WW), n)\n",
    "        vXX = HOSVD_rank_app(WW,r)\n",
    "        error[j] = np.linalg.norm(vectorize_tl(vXX)- X_ravel)/np.linalg.norm(X_ravel)\n",
    "          \n",
    "    return vXX, error\n",
    "\n",
    "\n",
    "def TIHT_HOSVD_proj_low(AA,yy,X,r,lamda = 1, itr = 100, num = 4): \n",
    "    \n",
    "    n = np.shape(X)\n",
    "    X_ravel = np.ravel(X)\n",
    "    \n",
    "    error = np.zeros(itr)\n",
    "    \n",
    "    vXX = torch.randn(n)*0\n",
    "\n",
    "    for j in range(itr):\n",
    "        \n",
    "        proj = proj_vals(AA,yy,np.array(vectorize_tl(vXX)))\n",
    "                           \n",
    "        remove_row = low_proj(proj, number = num)\n",
    "        A_1 = np.delete(AA,remove_row,axis = 0)\n",
    "        y_1 = np.delete(yy,remove_row,axis = 0)\n",
    "    \n",
    "        WW = np.array(vectorize_tl(vXX)) + (m/(m-num))*lamda* np.matmul(A_1.T, (y_1 - np.matmul(A_1, np.array(vectorize_tl(vXX)))))\n",
    "        WW = torch.reshape(torch.tensor(WW), n)\n",
    "        vXX = HOSVD_rank_app(WW,r)\n",
    "        error[j] = np.linalg.norm(vectorize_tl(vXX)- X_ravel)/np.linalg.norm(X_ravel)\n",
    "          \n",
    "    return vXX, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b624824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive_TIHT(AA,yy,X,r,lamda,mu = 1,itr=250,numb=5,thresh = 1.1):\n",
    "    \n",
    "    n = np.shape(X)\n",
    "    X_ravel = np.ravel(X)\n",
    "    \n",
    "    error = np.zeros(itr)\n",
    "    error_clip = np.zeros(itr)\n",
    "    delta_1_l = np.zeros(itr)\n",
    "    rho_1_l = np.zeros(itr)\n",
    "    rate_1_l = np.zeros(itr)\n",
    "    delta_2_l = np.zeros(itr)\n",
    "    rho_2_l = np.zeros(itr)\n",
    "    rate_2_l = np.zeros(itr)\n",
    "    \n",
    "    vXX = torch.randn(n)*0\n",
    "    vXX_unclip = torch.randn(n)*0\n",
    "\n",
    "    for j in range(itr):\n",
    "        \n",
    "        proj = proj_vals(AA,yy,np.array(vectorize_tl(vXX)))\n",
    "        \n",
    "        #before clipping\n",
    "        delta_1 = lamda*(np.linalg.norm(np.matmul(AA, vectorize_tl(vXX_unclip) - X_ravel))/np.linalg.norm(vectorize_tl(vXX_unclip) - X_ravel))**2\n",
    "        WW_unclip = np.array(vectorize_tl(vXX_unclip)) + mu*lamda* np.matmul(AA.T, (yy - np.matmul(AA, np.array(vectorize_tl(vXX_unclip)))))\n",
    "        WW_unclip = torch.reshape(torch.tensor(WW_unclip), n)\n",
    "        R_t = vectorize_tl(vXX_unclip) - X_ravel\n",
    "        vXX_unclip = HOSVD_rank_app(WW_unclip,r)\n",
    "        R_t1 = vectorize_tl(vXX_unclip) - X_ravel\n",
    "        rho_1 = (np.linalg.norm(proj_omega((1/np.sqrt(m)*AA.T)@(1/np.sqrt(m)*AA)@R_t,R_t,R_t1))/np.linalg.norm((1/np.sqrt(m)*AA)@R_t))**2\n",
    "        rate_1 = 2*np.sqrt(1-(2-mu*rho_1)*mu*delta_1)\n",
    "        delta_1_l[j] = delta_1\n",
    "        rho_1_l[j] = rho_1\n",
    "        rate_1_l[j] = rate_1\n",
    "        error[j] = np.linalg.norm(vectorize_tl(vXX_unclip)- X_ravel)/np.linalg.norm(X_ravel)\n",
    "\n",
    "        if delta_1 > thresh:\n",
    "            num = numb\n",
    "            remove_row = high_proj(proj, number = num)\n",
    "            A_1 = np.delete(AA,remove_row,axis = 0)\n",
    "            y_1 = np.delete(yy,remove_row,axis = 0)\n",
    "        \n",
    "        elif delta_1 < thresh:\n",
    "            num = numb \n",
    "            remove_row = low_proj(proj, number = num)\n",
    "            A_1 = np.delete(AA,remove_row,axis = 0)\n",
    "            y_1 = np.delete(yy,remove_row,axis = 0)\n",
    "    \n",
    "        else:\n",
    "            A_1 = AA\n",
    "            num = 0\n",
    "        \n",
    "        #after clipping\n",
    "        delta_2 = (m/(m-num))*lamda*(np.linalg.norm(np.matmul(A_1, vectorize_tl(vXX) - X_ravel))/np.linalg.norm(vectorize_tl(vXX) - X_ravel))**2\n",
    "        WW = np.array(vectorize_tl(vXX)) + (m/(m-num))*lamda*mu*np.matmul(A_1.T, (y_1 - np.matmul(A_1, np.array(vectorize_tl(vXX)))))\n",
    "        WW = torch.reshape(torch.tensor(WW), n)\n",
    "        R_t = vectorize_tl(vXX) - X_ravel\n",
    "        vXX = HOSVD_rank_app(WW,r)\n",
    "        R_t1 = vectorize_tl(vXX) - X_ravel\n",
    "        rho_2 = (m/(m-num))*lamda*(np.linalg.norm(proj_omega(A_1.T@A_1@R_t,R_t,R_t1))/np.linalg.norm(A_1@R_t))**2\n",
    "        rate_2 =  2*np.sqrt(1-(2-mu*rho_2)*mu*delta_2)\n",
    "        delta_2_l[j] = delta_2\n",
    "        rho_2_l[j] = rho_2\n",
    "        rate_2_l[j] = rate_2\n",
    "        error_clip[j] = np.linalg.norm(vectorize_tl(vXX)- X_ravel)/np.linalg.norm(X_ravel)\n",
    "    return delta_1_l, delta_2_l, rho_1_l, rho_2_l, rate_1_l, rate_2_l, error, error_clip\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871dcd97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
