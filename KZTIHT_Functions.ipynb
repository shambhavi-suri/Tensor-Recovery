{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fabe4fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "#KZTIHT for Tensor Recovery\n",
    "#########################\n",
    "\n",
    "##########################\n",
    "### Analysing Error ######\n",
    "##########################\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from numpy.random import rand, randn, choice, permutation\n",
    "from scipy.linalg import hadamard\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import tensorly as tl\n",
    "from tensorly import decomposition\n",
    "from tensorly.decomposition import parafac\n",
    "from scipy import linalg\n",
    "\n",
    "from scipy.linalg import dft\n",
    "from scipy.stats import ortho_group "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75322484",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining Measurement Matrices ##\n",
    "\n",
    "def gaussian_mx(m,N):\n",
    "    A = np.random.normal(0.0, 1.0, [m, N])\n",
    "    return A\n",
    "\n",
    "def hadamard_mx(m,N):\n",
    "    A = hadamard(N)\n",
    "    l = permutation(np.range(N))\n",
    "    return A[l[:m],:]\n",
    "\n",
    "def SJLT_mx(m,N,sp):    \n",
    "    delta = np.zeros((sp,N))\n",
    "    matrix = np.zeros((m,N))\n",
    "    sigma = np.zeros((m,N))\n",
    "    \n",
    "    for i in range(sp): \n",
    "        for j in range(N): \n",
    "            delta[i, j] = np.random.randint(2) * 2 - 1\n",
    "    \n",
    "    for i in range(N):\n",
    "        sparse_col = np.random.choice(m, sp, replace=False)\n",
    "        matrix[sparse_col,i] = delta[:,i]\n",
    "        \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e91dab93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_tl(X): ##Vectorisation for tensors\n",
    "    x=X.numpy()\n",
    "    x=x.reshape(-1)\n",
    "    return x\n",
    "\n",
    "def vectorize_np(X):  ##Vecorisation for numpy arrays\n",
    "    x=X\n",
    "    x=x.reshape(-1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f34e7020",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Thresholding operators #########\n",
    "\n",
    "def sparse_vect(x,s): ## s-sparse approximation\n",
    "    \n",
    "    x_1 = np.abs(x)\n",
    "    index = np.flip(np.argsort(x_1))[:s]\n",
    "    l = np.zeros(np.shape(x)[0])\n",
    "    l[index] = x[index]\n",
    "\n",
    "    return l\n",
    "\n",
    "def sparse_vect_random(x,s):\n",
    "    \n",
    "    index = np.random.choice(np.shape(x)[0], s, replace=False)\n",
    "    l = np.zeros(np.shape(x)[0])\n",
    "    l[index] = x[index]\n",
    "    \n",
    "    return l\n",
    "\n",
    "def random_low_rank_HOSVD(n,r,eps = 0.1):\n",
    "    C=np.random.normal(0,1,size=r)+eps\n",
    "    C=tl.tensor(C)\n",
    "    C.shape\n",
    "    X=C ##core tensor\n",
    "\n",
    "    U=[]\n",
    "    for i in range(len(n)):\n",
    "        M=np.random.normal(0,1,size=(n[i],n[i]))+eps\n",
    "        u,sigma,v=np.linalg.svd(M)\n",
    "        U.append(u[:,0:r[i]])\n",
    "\n",
    "    for i in range(len(n)):\n",
    "        X=tl.tenalg.mode_dot(X,U[i],i)\n",
    "    return X\n",
    "\n",
    "def random_low_rank_CP(n,r,eps = 0.1):   #### CP Rank r\n",
    "    #torch.manual_seed(0)\n",
    "    #np.random.seed(0)\n",
    "    \n",
    "    L = []\n",
    "    for i in range(0,len(n)):\n",
    "        C=np.random.normal(0,1,size=(n[i],r))+eps\n",
    "        L = L + [C]\n",
    "    \n",
    "    X = np.zeros(n)\n",
    "    for i in range(r):\n",
    "        U_r = np.array(L[0])[:,i]\n",
    "        for j in range(1, len(n)):\n",
    "            prod = np.array(L[j])[:,i]\n",
    "            U_r = np.multiply.outer(U_r,prod)\n",
    "        X = X + U_r\n",
    "        \n",
    "    C=tl.tensor(X) #Changing data frame to tensor\n",
    "    C.shape\n",
    "    return C\n",
    "\n",
    "def HOSVD_rank_app(tensor,r): ## HOSVD rank-r approximation\n",
    "    \n",
    "    core, factors = tl.decomposition.tucker(tensor.numpy(), r) #Decomposition function is used \n",
    "    answer = torch.tensor(tl.tucker_to_tensor([core, factors]))\n",
    "    \n",
    "    return answer\n",
    "\n",
    "def CP_rank_app(tensor,r):  ## CP rank-r approximation\n",
    "    \n",
    "    factors = parafac(tl.tensor(tensor), rank=r)\n",
    "    answer = tl.cp_to_tensor(factors)\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edea29d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TIHT_CP(AA,yy,X,r,lamda = 1, itr = 100): \n",
    "    \n",
    "    n = np.shape(X)\n",
    "    X_ravel = np.ravel(X)\n",
    "    \n",
    "    error = np.zeros(itr)\n",
    "    \n",
    "    vXX = torch.randn(n)*0 ##Random Initialisation\n",
    "\n",
    "    for j in range(itr):\n",
    "    \n",
    "        WW = np.array(vectorize_np(vXX)) + lamda*np.matmul(AA.T, (yy - np.matmul(AA, np.array(vectorize_np(vXX)))))\n",
    "        WW = torch.reshape(torch.tensor(WW), n)\n",
    "        vXX = CP_rank_app(WW,r)\n",
    "        error[j] = np.linalg.norm(vectorize_np(vXX)- X_ravel)/np.linalg.norm(X_ravel)\n",
    "        \n",
    "    return vXX, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfb28f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TIHT_HOSVD(AA,yy,X,r,lamda = 1, itr = 100): \n",
    "    \n",
    "    n = np.shape(X)\n",
    "    X_ravel = np.ravel(X)\n",
    "    \n",
    "    error = np.zeros(itr)\n",
    "    \n",
    "    vXX = torch.randn(n)*0\n",
    "\n",
    "    for j in range(itr):\n",
    "    \n",
    "        WW = np.array(vectorize_tl(vXX)) + lamda* np.matmul(AA.T, (yy - np.matmul(AA, np.array(vectorize_tl(vXX)))))\n",
    "        WW = torch.reshape(torch.tensor(WW), n)\n",
    "        vXX = HOSVD_rank_app(WW,r)\n",
    "        error[j] = np.linalg.norm(vectorize_tl(vXX)- X_ravel)/np.linalg.norm(X_ravel)\n",
    "        \n",
    "    return vXX, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae1c856d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KZIHT(A,b,x,s,gamma=1,itr=100): ## Selecting rows with replacement, gamma-step size for Kaczmarz\n",
    "    \n",
    "    error = np.zeros(itr)\n",
    "    m = np.shape(A)[0]\n",
    "    y = np.zeros(np.shape(x)[0])\n",
    "    \n",
    "    for k in range(itr): # Outer iteration for IHT updates\n",
    "        for j in range(m): #Inner iteration for Kaczmarz updates\n",
    "            \n",
    "            t = np.random.randint(m)\n",
    "            a = A[t,:]\n",
    "            y = y + gamma*(b[t] - a@y)*a/(np.linalg.norm(a)**2)\n",
    "                           \n",
    "        y = sparse_vect(y,s)\n",
    "        error[k] = np.linalg.norm(y-x)/np.linalg.norm(x)\n",
    "                             \n",
    "    return y,error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12856cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KZIHT_RR(A,b,x,s,gamma=1,itr=100): ## Selecting rows with replacement, gamma-step size for Kaczmarz\n",
    "    \n",
    "    error = np.zeros(itr)\n",
    "    m = np.shape(A)[0]\n",
    "    y= np.zeros(np.shape(x)[0])\n",
    "    \n",
    "    for k in range(itr): # Outer iteration for IHT updates\n",
    "        \n",
    "        t = permutation(np.arange(m))\n",
    "        \n",
    "        for j in range(m): #Inner iteration for Kaczmarz updates\n",
    "            \n",
    "            a = A[t[j],:]\n",
    "            y = y + gamma*(b[t[j]] - a@y)*a/(np.linalg.norm(a)**2)\n",
    "                           \n",
    "        y = sparse_vect(y,s)\n",
    "        error[k] = np.linalg.norm(y-x)/np.linalg.norm(x)\n",
    "        \n",
    "    return y,error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c92a4782",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KZIHT_CP(A,b,X,n,r,gamma = 1, itr = 100): ## n denotes dimensions of the tensor\n",
    "    \n",
    "    error = np.zeros(itr)\n",
    "    m = np.shape(A)[0]\n",
    "    \n",
    "    n = np.shape(X)\n",
    "    x = np.ravel(X)\n",
    "    \n",
    "    y = np.zeros(np.shape(x)[0])  \n",
    "    \n",
    "    for k in range(itr): # Outer iteration for IHT updates\n",
    "        for j in range(m): #Inner iteration for Kaczmarz updates\n",
    "            \n",
    "            t = np.random.randint(m)\n",
    "            a = A[t,:]\n",
    "            y = y + gamma*(b[t] - a@y)*a/(np.linalg.norm(a)**2)\n",
    "                           \n",
    "        WW = torch.reshape(torch.tensor(y), n)\n",
    "        y = vectorize_tl(CP_rank_app(WW,r))\n",
    "        error[k] = np.linalg.norm(y-x)/np.linalg.norm(x)\n",
    "                             \n",
    "    return y,error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "518befc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KZIHT_HOSVD(A,b,X,n,r,gamma = 1, itr = 100):\n",
    "    \n",
    "    error = np.zeros(itr)\n",
    "    m = np.shape(A)[0]\n",
    "    \n",
    "    n = np.shape(X)\n",
    "    x = np.ravel(X)\n",
    "    \n",
    "    y = np.zeros(np.shape(x)[0])    \n",
    "    \n",
    "    for k in range(itr): # Outer iteration for IHT updates\n",
    "        for j in range(m): #Inner iteration for Kaczmarz updates\n",
    "            \n",
    "            t = np.random.randint(m)\n",
    "            a = A[t,:]\n",
    "            y = y + gamma*(b[t] - a@y)*a/(np.linalg.norm(a)**2)\n",
    "                           \n",
    "        WW = torch.reshape(torch.tensor(y), n)\n",
    "        y = vectorize_tl(HOSVD_rank_app(WW,r))\n",
    "        error[k] = np.linalg.norm(y-x)/np.linalg.norm(x)\n",
    "                             \n",
    "    return y,error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3b6afe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KZPT_HOSVD_RR(A,b,X,n,r, period = 1,gamma = 1, itr = 100):\n",
    "    \n",
    "    error = np.zeros(itr)\n",
    "    m = np.shape(A)[0]\n",
    "    \n",
    "    n = np.shape(X)\n",
    "    x = np.ravel(X)\n",
    "    \n",
    "    y = np.zeros(np.shape(x)[0])    \n",
    "    t = permutation(np.arange(m))\n",
    "            \n",
    "    for k in range(itr): # Outer iteration for IHT updates\n",
    "        \n",
    "        for j in range(m): #Inner iteration for Kaczmarz updates\n",
    "            \n",
    "            a = A[t[j],:]\n",
    "            y = y + gamma*(b[t[j]] - a@y)*a/(np.linalg.norm(a)**2)\n",
    "                                     \n",
    "            if (j+1)%period == 0:\n",
    "                WW = torch.reshape(torch.tensor(y), n)\n",
    "                y = vectorize_tl(HOSVD_rank_app(WW,r))\n",
    "                \n",
    "        error[k] = np.linalg.norm(vectorize_np(y)-x)/np.linalg.norm(x)\n",
    "                             \n",
    "    return y,error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f46a4dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KZIHT_HOSVD_RR(A,b,X,n,r,gamma = 1, itr = 100):\n",
    "    \n",
    "    error = np.zeros(itr)\n",
    "    m = np.shape(A)[0]\n",
    "    \n",
    "    n = np.shape(X)\n",
    "    x = np.ravel(X)\n",
    "    \n",
    "    y = np.zeros(np.shape(x)[0])    \n",
    "            \n",
    "    for k in range(itr): # Outer iteration for IHT updates\n",
    "        \n",
    "        t = permutation(np.arange(m))\n",
    "        \n",
    "        for j in range(m): #Inner iteration for Kaczmarz updates\n",
    "            \n",
    "            a = A[t[j],:]\n",
    "            y = y + gamma*(b[t[j]] - a@y)*a/(np.linalg.norm(a)**2)\n",
    "                                     \n",
    "        WW = torch.reshape(torch.tensor(y), n)\n",
    "        y = vectorize_tl(HOSVD_rank_app(WW,r))\n",
    "        error[k] = np.linalg.norm(vectorize_np(y)-x)/np.linalg.norm(x)\n",
    "                             \n",
    "    return y,error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "026200c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proj_vals(A,b,x_it,gamma = 1):\n",
    "    \n",
    "    error = np.zeros(itr)\n",
    "    m = np.shape(A)[0]\n",
    "    \n",
    "    n = np.shape(X)\n",
    "    \n",
    "    proj = []\n",
    "    \n",
    "    for j in range(m): #Inner iteration for Kaczmarz updates\n",
    "        a = A[j,:]\n",
    "        proj_val = x_it + gamma*(b[j] - a@x_it)*a/(np.linalg.norm(a)**2)\n",
    "        proj = proj + [np.linalg.norm(proj_val-x_it)]\n",
    "    \n",
    "    return proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c77a701",
   "metadata": {},
   "outputs": [],
   "source": [
    "def high_proj(a, number = 5):\n",
    "\n",
    "    res = sorted(range(len(a)), key = lambda sub: a[sub])[-number:]\n",
    "    return res\n",
    "\n",
    "def TIHT_HOSVD_proj(AA,yy,X,r,lamda = 1, itr = 100, num = 2): \n",
    "    \n",
    "    n = np.shape(X)\n",
    "    X_ravel = np.ravel(X)\n",
    "    \n",
    "    error = np.zeros(itr)\n",
    "    \n",
    "    vXX = torch.randn(n)*0\n",
    "\n",
    "    for j in range(itr):\n",
    "        \n",
    "        proj = proj_vals(AA,yy,np.array(vectorize_tl(vXX)))\n",
    "                           \n",
    "        remove_row = high_proj(proj, number = num)\n",
    "        A_1 = np.delete(AA,remove_row,axis = 0)\n",
    "        y_1 = np.delete(yy,remove_row,axis = 0)\n",
    "    \n",
    "        WW = np.array(vectorize_tl(vXX)) + (m/(m-num))*lamda* np.matmul(A_1.T, (y_1 - np.matmul(A_1, np.array(vectorize_tl(vXX)))))\n",
    "        WW = torch.reshape(torch.tensor(WW), n)\n",
    "        vXX = HOSVD_rank_app(WW,r)\n",
    "        error[j] = np.linalg.norm(vectorize_tl(vXX)- X_ravel)/np.linalg.norm(X_ravel)\n",
    "          \n",
    "    return vXX, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e8b4f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
